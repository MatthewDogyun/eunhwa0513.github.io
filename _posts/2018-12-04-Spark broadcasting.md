---
layout: post
title: Spark broadcastingì„ ì´ìš©í•´ ê¸°ì¡´ ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì†ë„ ê°œì„ í•˜ê¸°
subheading: JupyterHubë¥¼ êµ¬ì¶•í–ˆë‹¤ë©´ ì‚¬ìš©ì ë³„ í™˜ê²½ê³¼ ë¦¬ì†ŒìŠ¤ë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•œ ì„¤ì •ë°©ë²•ì„ ì•Œì•„ë´…ì‹œë‹¤.
author: ê¹€ì—°ìˆ˜ | Data Analyst
categories: ë¨¸ì‹ ëŸ¬ë‹
tags: python sklearn ml spark
sidebar: []
---

# Spark Broadcast

> ìš°ë¦¬ì—ê²Œ í•„ìš”í•œ ê²ƒì€ inference íš¨ìœ¨ì„± ğŸ˜
> 
> > ê¸°ì¡´ python ml ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë‹¤ëŸ‰ì˜ ë°ì´í„°ë¥¼ ë¹ ë¥´ê²Œ ì²˜ë¦¬ë¥¼ í•´ì•¼ í•  ë•Œ!  Spark broadcastingì„ ì´ìš©í•´ inference ì†ë„ë¥¼ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

  

## Sparkì˜ ê³µìœ  ë³€ìˆ˜

----------

`ì•„í”¼ì¹˜ ìŠ¤íŒŒí¬`ëŠ” SQL, ë¨¸ì‹ ëŸ¬ë‹ ë“± ì²˜ë¦¬ë¥¼ ìœ„í•œ ê¸°ë³¸ ì œê³µ ëª¨ë“ˆì´ ìˆëŠ”  `ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬ìš© í†µí•© ë¶„ì„ ì—”ì§„`ì…ë‹ˆë‹¤.

  
ì¼ë°˜ì ì¸ ìŠ¤íŒŒí¬ ì—°ì‚°ì´ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‹¤í–‰ë  ë•Œ í•¨ìˆ˜ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë³€ìˆ˜ëŠ” ê° í´ëŸ¬ìŠ¤í„°ì— ë³µì œë˜ê³  ê° ë…¸ë“œ ì—°ì‚°ì—ì„œëŠ” ë…ë¦½ì ì…ë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„° ìƒì—ì„œ ë³€ìˆ˜ë¥¼ ê³µìœ í•˜ëŠ” ê²ƒì€ ë¹„íš¨ìœ¨ì ì´ê¸° ë•Œë¬¸ì¸ë°, ì¼ë°˜ì ì¸ ì—°ì‚° íŒ¨í„´ì„ ì§€ì›í•˜ê¸° ìœ„í•´ ì•„ë˜ì™€ ê°™ì€ ê³µìœ  ë³€ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤ .

-   broadcast variables : í° ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ”ë° ì‚¬ìš©
-   Accumulators variables : íŠ¹ì • ì»¬ë ‰ì…˜ì˜ ì •ë³´ë¥¼ ì§‘ê³„í•˜ëŠ” ë° ì‚¬ìš©

ì˜¤ëŠ˜ì€  `broadcast variables`ì— ëŒ€í•˜ì—¬ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

  

## Spark broadcast ë€?

----------

broadcast ë³€ìˆ˜ëŠ” ì½ê¸° ì „ìš© ë³€ìˆ˜ì…ë‹ˆë‹¤. ëª¨ë“  ë…¸ë“œì— í° input ë°ì´í„°ì…‹ì„ ì œê³µí•  ë•Œ íš¨ê³¼ì ì¸ ë°©ë²•ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ì‚¬ìš©í•˜ë©´ íš¨ìœ¨ì ì¸ broadcast ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ê³„ì‚° ë¹„ìš©ì„ ì¤„ì¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

  

ìŠ¤íŒŒí¬ì˜ ì•¡ì…˜ë“¤ì€ ê¸°ë³¸ì ìœ¼ë¡œ ì—¬ëŸ¬ ë‹¨ê³„ì˜ ì§‘í•©ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ”ë°, ìë™ì ìœ¼ë¡œ ê° ë‹¨ê³„ì— í•„ìš”í•œ ê³µìœ  ë³€ìˆ˜ë“¤ì„ broadcastí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

Broadcast ë³€ìˆ˜ëŠ” RDDë‚˜ Dataframeê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ë°ì´í„°ëŠ” serialized ìºì‹±ë˜ê³  deserialized ë˜ì–´ ê° í…ŒìŠ¤í¬ë¡œ ë„˜ì–´ê°€ê²Œ ë©ë‹ˆë‹¤.)

  
í˜¸ì¶œ ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```ini
sc = SparkContext()
var = Array(4,5,6) # ì‚¬ìš©í•  ê³µìœ  ë³€ìˆ˜ var

broadcastvar = sc.broadcast(var)

```

ì¼ë‹¨ broadcast variableì´ ë§Œë“¤ì–´ì§€ë©´, í´ëŸ¬ìŠ¤í„°ìƒì˜ ëª¨ë“  í•¨ìˆ˜ì— ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì¦‰,  **varì€ í•œ ë²ˆ ì´ìƒ ë…¸ë“œì— ì˜¬ë¼ê°€ì§€ ì•Šê²Œ**  ë©ë‹ˆë‹¤.)

ì°¸ê³ ë¡œ, í•œ ë²ˆ ìƒì„±ëœ broadcastvar ê°ì²´ëŠ” ì´í›„ ìˆ˜ì •ë  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

  
broadcast ëœ ê°’ì„ ì´ìš©í•˜ê¸° ìœ„í•´ì„œëŠ”  `value ë©”ì†Œë“œ`ë¥¼ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.

```markdown
# value ê°’ì— ì•¡ì„¸ìŠ¤ í•˜ê¸° ìœ„í•¨
broadcastvar.value

# output
> Array(4,5,6)

```

  

## sklearnì— spark broadcastë¥¼ ì ìš©í•´ inference í•˜ê¸°

----------

pythonì—ì„œ ê°€ì¥ ë§ì´ ì´ìš©ë˜ëŠ” mechine learning libraryëŠ” sklearnì¼ ê²ƒì…ë‹ˆë‹¤. sklearn ì—ì„œëŠ” ë³´í†µ pandas dataframe ì„ í™œìš©í•œ ë°ì´í„°ë¥¼ fití•˜ê³  predict í•˜ê²Œ ë©ë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´, KNN (K-Nearest Neighbors)ê³¼ ê°™ì€ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ê²Œ ëœë‹¤ë©´ ìš°ë¦¬ëŠ” ê° key ê°’ì— ëŒ€í•œ ê°ê°ì˜ kê°œì˜ neighborsë¥¼ ëª¨ë‘ êµ¬í•´ì•¼í•©ë‹ˆë‹¤. ì¦‰,  **key ê°’ í•˜ë‚˜í•˜ë‚˜ì— ëª¨ë“  ë°ì´í„°ë¥¼ ì—°ì‚°**í•˜ê²Œ ë©ë‹ˆë‹¤.ê²°êµ­ inference ì‹œê°„ì´ ì—„ì²­ë‚˜ê²Œ ê¸¸ì–´ì§ˆ ìˆ˜ ë°–ì— ì—†ëŠ” êµ¬ì¡°ê°€ ë©ë‹ˆë‹¤.

ì´ëŠ”  **sklearn modelì„ broadcast í•˜ëŠ” ë°©ì‹**ì„ í™œìš©í•´ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

  

ì˜ˆì œ ì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ( knn model ì‚¬ìš© )

```python
def knn_regressor_broadcast(data_pd, neighbors=100, n_partitions=10, weights = "uniform"):

  # X_train, y_train, X_test, y_test ì˜ ê²½ìš° pandas dataframe í˜•íƒœ
  

  # ëª¨ë¸ fit
  knn = KNeighborsRegressor(n_neighbors = neighbors, weights = weights)
  model = knn.fit(X_train, y_train)
  
  # ì—¬ëŸ¬ ë°°ì¹˜ë¡œ ëŒë¦¬ê¸° ìœ„í•œ í•¨ìˆ˜
  def batch(value):
    yield list(value)
    
  rdd = sc.parallelize(X_test, n_partitions).zipWithIndex()
  b_model = sc.broadcast(model)
  result = rdd.mapPartitions(batch).map(lambda value: ([x[0] for x in value], [x[1] for x in value])).flatMap(lambda x: zip(x[1], b_model.value.predict(x[0])))
  
  result = result.collect()

  return result

```

ìœ„ì™€ ê°™ì´  **modelì„ broadcast + rdd test data**ë¥¼ ì‚¬ìš©í•˜ì Pandas dataframeì„ ì´ìš©í•´ predictë¥¼ í•˜ì˜€ì„ ë•Œ Runtime errorrkê°€ ë‚¬ë˜ ëª¨ë¸ì„ ì•½ 5ë¶„ ë‚´ì™¸ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤ ğŸ‘ğŸ‘

  

ë¶€ê°€ì ì¸ ì½”ë“œ ì„¤ëª…ì„ ì ì‹œ í•˜ìë©´

mapPartitionsì˜ ê²½ìš° ë‚˜ëˆ ì§„ partitionë‚´ì—ì„œ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê²Œ í•´ì¤ë‹ˆë‹¤

```python
rdd = sc.parallelize([1, 2, 3, 4], 2)
def f(iterator): yield sum(iterator)
rdd.mapPartitions(f).collect()

# output
> [3, 7]

```

ì¦‰, broadcastëœ ëª¨ë¸ì— test ë°ì´í„°ë¥¼ batch í˜•íƒœë¡œ ë¶„ì‚° ì²˜ë¦¬ê°€ ê°€ëŠ¥í•´ì§„ë‹¤ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

  

## ì°¸ê³  ìë£Œ

----------

ğŸ‘‰  [About advaced spark programming - spark broadcast](https://www.tutorialspoint.com/apache_spark/advanced_spark_programming.htm)

ğŸ‘‰  [Spark Broadcast Varibales](https://sparkbyexamples.com/spark/spark-broadcast-variables/)